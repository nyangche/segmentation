import streamlit as st
import os
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI

from main import run_pipeline
from segmentation import draw_focus_overlay_by_class_sam

# GPT API ì„¤ì •
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# GPTë¡œ í›„ë³´ í´ë˜ìŠ¤ ëª©ë¡ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­
def translate_class_list_to_korean(class_name_candidates):
    system_prompt = (
        "ë‹¤ìŒì€ ê°ì²´ íƒì§€ ê²°ê³¼ë¡œ ë‚˜ì˜¨ í´ë˜ìŠ¤ ì´ë¦„ì…ë‹ˆë‹¤. "
        "ì´ ëª©ë¡ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë‹¨ì–´ ì‚¬ì´ ë„ì–´ì“°ê¸°ê¹Œì§€ í•œêµ­ì–´ë‹µê²Œ ì¨ì£¼ì„¸ìš”.\n"
        f"{', '.join(class_name_candidates)}"
    )

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”"}
        ]
    )

    return response.choices[0].message.content.strip()

# ìì—°ì–´ë¡œ ê°•ì¡°í•  ê°ì²´ë¥¼ ì…ë ¥í•˜ë©´, ì›ë˜ class_nameì„ ë°˜í™˜
def get_target_class_from_prompt(prompt, class_name_candidates):
    translated_korean = translate_class_list_to_korean(class_name_candidates)

    system_prompt = (
        "ë‹¤ìŒì€ ê°ì²´ íƒì§€ ê²°ê³¼ë¡œ ë‚˜ì˜¨ ì˜ì–´ í´ë˜ìŠ¤ ì´ë¦„ ëª©ë¡ì…ë‹ˆë‹¤.\n"
        f"ê°ì²´ í›„ë³´ ëª©ë¡ (í•œê¸€): {translated_korean}\n"
    )
    user_prompt = f"ê°•ì¡°í•  ê°ì²´: {prompt}"

    # âŒ ì‚¬ìš©ì ì¶œë ¥ ì œê±°
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )

    result = response.choices[0].message.content.strip().lower()

    for candidate in class_name_candidates:
        if candidate.lower() in result:
            return candidate

    return "none"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Segmentation Demo", layout="centered")
st.title("ğŸ¤”Perceive Like Humans: Semantic Instance Grouping for Image SegmentationğŸ’­")

# ì¤‘ê°„ í¬ê¸°ì˜ ë¶€ì œëª© + ëª¨ë¸ ì„¤ëª…
st.markdown("#### ê¹€ë¯¼ì†” í•œì±„í—Œ ìµœë‹¤ë¹ˆ ìµœí˜œì£¼")
st.markdown("ì‚¬ìš©ìì˜ ìì—°ì–´ ì˜ë„ì— ë”°ë¼ ì¤‘ìš”í•œ ê°ì²´ë¥¼ ê°•ì¡°í•´ì£¼ëŠ” ì¸ê°„ ì¤‘ì‹¬ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸")

# êµ¬ë¶„ì„ 
st.markdown("---")

# ìƒíƒœ ì €ì¥ ì´ˆê¸°í™”
if "image_path" not in st.session_state:
    st.session_state.image_path = None
if "grouped" not in st.session_state:
    st.session_state.grouped = None
if "instance_mask_array" not in st.session_state:
    st.session_state.instance_mask_array = None
if "output_dir" not in st.session_state:
    st.session_state.output_dir = None
if "class_names" not in st.session_state:
    st.session_state.class_names = None
if "colored_mask" not in st.session_state:
    st.session_state.colored_mask = None
if "color_map" not in st.session_state:
    st.session_state.color_map = None
if "translated_list" not in st.session_state:
    st.session_state.translated_list = None

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "png"])

if uploaded_file:
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    upload_dir = os.path.join("static", "uploads")
    os.makedirs(upload_dir, exist_ok=True)
    image_path = os.path.join(upload_dir, f"{timestamp}_{uploaded_file.name}")

    with open(image_path, "wb") as f:
        f.write(uploaded_file.read())

    st.session_state.image_path = image_path
    st.image(image_path, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", width=400)

    # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    if st.button("â‘  ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰"):
        st.info("ì´ë¯¸ì§€ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
        overlay_path, output_dir, grouped, instance_mask_array, colored_mask, color_map = run_pipeline(image_path)

        st.session_state.grouped = grouped
        st.session_state.instance_mask_array = instance_mask_array
        st.session_state.colored_mask = colored_mask
        st.session_state.color_map = color_map
        st.session_state.output_dir = output_dir
        st.session_state.class_names = list(sorted(set(obj["class_name"] for obj in grouped)))
        st.session_state.translated_list = translate_class_list_to_korean(st.session_state.class_names)

        st.success("ë¶„ì„ ì™„ë£Œ! ğŸ‰")

# í•­ìƒ ê°ì²´ í›„ë³´ ëª©ë¡ í‘œì‹œ
if st.session_state.translated_list:
    st.markdown("**ê°ì²´ í›„ë³´ ëª©ë¡:** " + st.session_state.translated_list)

# ê°•ì¡° ìš”ì²­ ì…ë ¥
if st.session_state.class_names:
    prompt = st.text_input("â‘¡ ê°•ì¡°í•  ê°ì²´ë¥¼ ì…ë ¥í•˜ì„¸ìš”!")

    if st.button("â‘¢ ê°•ì¡° ì‹¤í–‰"):
        target_class = get_target_class_from_prompt(prompt, st.session_state.class_names)

        if target_class.lower() not in ["ì—†ìŒ", "none", "no"]:
            focus_output_path = os.path.join(st.session_state.output_dir, "focus_overlay.png")
            draw_focus_overlay_by_class_sam(
                st.session_state.image_path,
                st.session_state.instance_mask_array,
                st.session_state.grouped,
                target_class,
                focus_output_path,
            )

            # âœ… ì¤„ë°”ê¿ˆ ê°•ì¡° ë©”ì‹œì§€
            st.success(f"ê°•ì¡° ì™„ë£Œ! âœ…\n\nğŸ‘‰ ê°•ì¡°ëœ ê°ì²´: `{target_class}`")
            st.image(focus_output_path, caption="ê°•ì¡°ëœ ê°ì²´ ê²°ê³¼", use_container_width=True)
        else:
            st.warning("GPT íŒë‹¨: ê°•ì¡°í•  í´ë˜ìŠ¤ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ê°•ì¡°ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")